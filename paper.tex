% vim: set nowrap tw=0:
\documentclass[a4paper]{scrartcl}
\usepackage{defaultstyle}
\usepackage{localstyle}

\newcommand{\comment}[1]{}%\textsf{#1}}

\title{AppPAL for Android\\
Capturing and Checking App Installation Policies}
\author{Joseph Hallett \and David Aspinall}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
  % \begin{itemize}
  %   \item \comment{Sentence 1: State the problem}
  When a user buys an app on Android they can only judge available apps based only on the information presented to them by the store.
  %   \item \comment{Sentence 2: Why is it an interesting problem}
  Employers must rely on employees using company devices properly to enforce security policies about apps at work.
  Some users spend time to pick apps with care others don't.
  This can cause frustration when they realise what data the apps have access to.
  %   \item \comment{Sentence 3: What does my solution achieve}
  We present AppPAL: a policy language that can enforce app installation policies.
  Policies use statements from third parties and delegation relationships.
  %   \item \comment{Sentence 4: What follows from my solution}
  This gives us a rigorous and flexible framework for enforcing and comparing and app policies; and the trust relationships surrounding them.
  % \end{itemize}
\end{abstract}

\section{Introduction \comment{1 page}}
\label{sec:introduction}

%\comment{The problem is\ldots}
How do you pick which apps to install on your phone?  
App stores give some information about their apps; such as permissions and review scores.
Android apps show a confusing list of permissions (\autoref{fig:facebook}).
Whilst improving, users don't all understand how this relates to their device~\citep{Felt:2012hm,Thompson:2013eb}.
Ultimately the decision which apps to use must be made by the user.

Not all apps are suitable. 
There is a large amount of \ac{pus} available for Android~\citep{Truong:2014bi,Svajcer:2013tp}. 
Employees are increasingly using their own phones for work (the \ac{byod} scheme.)
Their company may want to restrict which apps their employees can use.
The \ac{ciso} or IT department may set a policy to prevent information leaks.
Some users worry apps will misuse their personal data.
They avoid apps which can access their location, or contact data.
They apply their own personal security policy when downloading apps.

Currently these policies are enforced by hand.
This is error-prone and can be inconsistent.
A better solution is to use a logic of authorization.
The policy can be written in the logic and enforced automatically.

\begin{figure}
  \centering
  \includegraphics[width=0.3\linewidth]{figures/facebook.png}
  \caption{Security information presented when a user downloads the Facebook app.}
\label{fig:facebook}
\end{figure}

%\comment{My contribution is\ldots}
We present AppPAL, an authorization logic for reasoning about Android apps.
The language is an instantiation of SecPAL~\citep{Becker:2006vh} tailored to making statements about apps.
It allows us to reason about apps using statements from third parties.
We can express trust relationships in these speakers and use constraints to perform additional checks at evaluation time.
This allows us to enforce deeper and more complex policies than existing policy tools like Kirin~\citep{Enck:2009ko}.

Specifically we have:
\begin{itemize}
  \item 
    Described a scenario where a user has a policy they want to enforce for their employees~(\autoref{sec:problem}.) 
    We show how the trust relationships in a system can be difficult to see;
      and how AppPAL makes the trust between users explicit.
  \item 
    Shown how the user's policy could be implemented using AppPAL~(\autoref{sec:idea}); 
      and describe what AppPAL would check for an app to meet this policy.
    
  \item Implemented the AppPAL language.  
    Our implementation runs on Android (\autoref{sec:details}.)
    We show how we have tailored the language to Android (\autoref{ssec:language}),
      how we evaluate it (\autoref{ssec:eval}),
      and some idiomatic policies (\autoref{ssec:idioms}.)
\end{itemize}

\section{The problem\comment{1 page}}
\label{sec:problem}

Suppose \emph{Alice} works for \emph{Bob}.
Bob allows Alice to use her personal phone as a work phone, but he has some specific concerns.
\begin{itemize}
  \item Alice shouldn't have any apps that can track her movements.
    The testing labs are at a secret location and it mustn't be leaked.
  \item Apps should come from a reputable source, such as the Play store.
  \item Bob uses an \ac{av} program by McAfee. 
    It should check all apps before they're installed.
\end{itemize}

To ensure this policy is fully met Alice could promise to follow it; but this is error-prone---what if she makes a mistake or misses something?
Bob's policy could be implemented using existing tools.
\emph{Google's Device Policy for Android}\footnote{\url{https://play.google.com/store/apps/details?id=com.google.android.apps.enterprise.dmagent}}
  could configure Alice's device to disallow apps from outside the Play Store.
Various tools~\citep{Backes:2012vm,Jeon:2012ki,Hornyack:2011wq} can control the permissions or data an app can get.
These could be used to used to ensure no location data is ever obtained.
Alternately other tools~\citep{Enck:2009ko,Fritz:2013vi,Gordon:2015et} could check that the locations are ever leaked to the web.
Various anti-virus programs are available for Android---one could be installed on Alice's phone.

Whilst we \emph{could} implement Bob's policy using existing tools, it isn't a great solution.
It isn't flexible, Alice needs to alter and remove the software on her phone if Bob changes his policy or she changes jobs.
It isn't clear what an app must do to be installed, or what checks must have been done if it already has been put on the phone.
The link between Alice, the user; Bob, the policy setter; and the tools Bob trusts to implement his policy isn't immediately apparent.

This last point is particularly pertinent with respect to \textsc{CVE-2015-2077}.
In 2015 Lenovo was found to be shipping laptops with the \emph{Superfish} malware pre-installed.
Lenovo had also installed an \ac{av} package on their laptops; this \ac{av} did recognise Superfish as malware.
Unfortunately they had configured it to ignore Superfish\footnote{The malware was an ad framework designed to show users products similar to those they viewed on the web.  Unfortunately it did so by man-in-the-middling all SSL traffic using a shared private key.}.

From a user's perspective there was a delegation of trust to Lenovo to detect malware.
Lenovo then delegated further to McAfee to supply the antivirus; but left an exception that they would allow Superfish.
A user might wonder where the breach of trust occurred and who is to blame?  
Is it the \ac{av} failing to spot the malware? 
Has someone else configured something incorrectly?
How should they fix the problem?

If we write this in the AppPAL policy language the cause of the breach of trust becomes apparent; as does the fix.
\begin{lstlisting}[numbers=left, escapeinside={@}{@}, label={lst:lenovo}]
"user" says "lenovo" can-say inf File isSafe. @\label{lst:lenovo_trust}@
"lenovo" says "mcafee" can-say inf File isSafe.
"lenovo" says "C:\System\superfish" isSafe. @\label{lst:lenovo_unsafe}@
\end{lstlisting}
The fault lies with \autoref{lst:lenovo_unsafe}.  
Lenovo has caused the problem (they \emph{said} it was safe).
The fix is to revoke this statement, or to revoke \autoref{lst:lenovo_trust} and find a different \ac{av} supplier.

It is important to stress that we are not trying to solve the problem of detecting malware.
There are many tools, and much research, that already does this.
Our problem is different. 
Given there are some apps you want and others you don't:
  how can you express your preferences in such a way that they can be enforced automatically.
Further more how can we show the trust relationships used to make these decisions clearly and precisely.

\section{My idea \comment{2 pages}}
\label{sec:idea}

Returning to Alice and Bob's dilemma in \autoref{sec:problem}, we propose a solution.
Instead of using several different tools to enforce Bob's policy disjointedly, we use an authorization logic.
In \autoref{lst:corporate} we give an AppPAL policy implementing Bob's app concerns on Alice's phone.
A pictorial representation, is given in \autoref{fig:bobs_policy}; color is used to split statements by each speaker.

\begin{figure}
  \includegraphics{figures/bob-policy.eps}
  \caption{Pictorial representation of Alice's app install policy.}
\label{fig:bobs_policy}
\end{figure}

AppPAL is an instantiation of SecPAL~\citep{Becker:2006vh} for app installation policies. 
SecPAL is a logic of authorization for access control decisions in distributed systems.
It has a clear and readable syntax, as well as rich mechanisms for delegation and constraints.
SecPAL has already been used as a basis for other policy languages in areas such as privacy preferences~\citep{Becker:2009ula} and data-sharing~\citep{Aziz:2011vt}.
We present AppPAL as a new version of SecPAL, targeting apps on mobile devices.

\begin{lstlisting}[label={lst:corporate}, 
                   caption={An AppPAL policy implementing Bob's security requirements},
                   float,
                   numbers=left,
                   escapeinside={@}{@}]
"alice" says "bob" can-say inf App isInstallable. @\label{lst:corporate_1}@
"bob" says App isInstallable @\label{lst:corporate_2}@
  if "no-tracking-policy" isMetBy(App),
     "reputable-source-policy" isMetBy(App),
     "anti-virus-policy" isMetBy(App).
"bob" says "reputable-source-policy" isMetBy(App) @\label{lst:corporate_3}@
  if App isBuyable.
"bob" says "google-play" can-say 0 App isBuyable. @\label{lst:corporate_4}@
"bob" says "anti-virus-policy" isMetBy(App) @\label{lst:corporate_5}@
  if App isAnApp
  where
    mcAfeeVirusCheck(App) = False.
"bob" says "no-location-permissions" can-act-as "no-tracking-policy". @\label{lst:corporate_6}@
"bob" says "no-location-permissions" isMetBy(App) @\label{lst:corporate_7}@
  if App isAnApp
  where
    hasPermission(App, "ACCESS_FINE_LOCATION") = False,
    hasPermission(App, "ACCESS_COURSE_LOCATION") = False.
\end{lstlisting}

In \autoref{lst:corporate_1} Alice gives Bob the ability to specify whether an \code{App} (a variable) \code{isInstallable} (a predicate).
She allows him to delegate the decision further if he chooses (\code{can-say inf}).
Next in \autoref{lst:corporate_2} Bob specifies his concerns as policies to be met (the \code{isMetBy()} predicate that takes an app as its argument).
If Bob can be convinced all these policies are met then he will say the \code{App isInstallable}.
In \autoref{lst:corporate_3} and \autoref{lst:corporate_4} Bob specifies that an app meets the \code{reputable-source-policy} if the \code{App isBuyable};
  with \code{"google-play"} specified as the decider of what is buyable or not.
This time Google is not allowed to delegate the decision further (\code{can-say 0}).
In other words Google is not allowed to specify Amazon as a supplier of apps as well.
Google must say what is buyable directly for Bob to accept it.
Bob specifies the \code{"anti-virus-policy"} in \autoref{lst:corporate_5}.
Here we use a constraint.
When checking the policy the \code{mcAfeeVirusCheck} should be run on the \code{App}.
Only if this returns \code{False} will the policy be met.
To specify the \code{"no-tracking-policy"} Bob says that the \code{"no-location-permissions"} rules implement the \code{"no-tracking-policy"} (\autoref{lst:corporate_6}).
Bob specifies this in \autoref{lst:corporate_7} by checking the app is missing two permissions.

Say Alice wants to install a new app (\code{com.facebook.katana}) on her phone.
To meet Bob's policy the AppPAL policy checker needs to collect statements to show the app meets the \code{isInstallable} predicate.
Specifically it needs:
\begin{description}
  \item[\texttt{"bob" says "com.facebook.katana" isAnApp.}] 
    A simple typing statement that can be generated for all apps as they are encountered.
  \item[\texttt{"google-play" says "com.facebook.katana" isBuyable.}] 
    Required to convince Bob the app came from a reputable source. 
    It should be able to obtain this statement from the Play store as the app is available there.
  \item[\texttt{"bob" says "anti-virus-policy" isMetBy("com.facebook.katana").}]
    She can obtain this by running the \ac{av} program on her app.
  \item[\texttt{"bob" says "no-locations-permissions" isMetBy("com.facebook.katana").}]
    Needed to show the App meets Bob's no-tracking-policy.
    Bob will say this if after examining the app the location permissions are missing.
\end{description}
These last two statements require the checker to do some extra checks to satisfy the constraints.
To get the third statement it must run the \ac{av} program on her app and check the result.
The results from the \ac{av} program may change with time as it's signatures are updated.  
Consequently the checker must re-run this check every time it wants to obtain the statement connected to the constraint.
For the forth statement the checker needs to check the permissions of the app.
It does this by looking in the \texttt{MANIFEST.xml} inside the app itself.

In this scenario we have imagined Alice wanting to check the apps as she installs them.
Alternatively we could imagine Bob wanting a personalised app store where all apps sold meet his policy.
With AppPAL this can be implemented by taking an existing store and selectively offering only the apps which meet the policy.


\section{The details \comment{5 pages}}
\label{sec:details}

AppPAL is implemented as a library for Android. 
A standalone Java version also exists for testing.  
The parser is implemented using ANTLR4.
Code, tests, and prebuilt APKs are available from Github\footnote{\url{https://github.com/bogwonch/AppPAL}}.

\subsection{The Language}
\label{ssec:language}

The structure of an AppPAL assertion is shown in \autoref{fig:assertion}.

\begin{figure}
  \centering
  \begin{equation*}\small
    \begin{array}{r l}
      \overbrace{\text{\ttfamily "user"}}^{\text{speaker}} & 
      \text{\ttfamily says }\overbrace{\overbrace{\text{\ttfamily App }}^{\text{subject}}\overbrace{\text{\ttfamily isInstallable}}^{\text{predicate}}}^{\text{fact}} \\
      & \overbrace{\text{\ttfamily if App isFree}}^{\text{condition}} \\
      & \overbrace{\text{\ttfamily where hasPermission(App, "INTERNET") = True}}^{\text{constraint}}. 
    \end{array}
  \end{equation*}
  \caption{Structure of an AppPAL assertion.}
\label{fig:assertion}
\end{figure}

In the \citeauthor{Becker:2006vh}'s paper~\citep{Becker:2006vh} they leave the choice of predicates, and constraints for their SecPAL open.
With AppPAL we make explicit our predicates and how they relate to Android.  
Some of these predicates require arguments.
We add a light typing system to help ensure these predicates have the correct arguments.

Specifically we define the following predicates:
\begin{description}
  \item[\texttt{App isAnApp}, \texttt{Policy isAPolicy}\ldots] 
    Simple typing relations.  
    The app \text{App} is an App, and so on.
  
  \item[\texttt{App isInstallable}]
    Used to indicate that an App meets the install policy for the device.
    Showing an app satisfies this predicate is usually the goal of evaluating AppPAL.

  \item[\texttt{Policy isMetBy(App)}]
    Policies let you split app behaviour into sub-policies.
    For example in \autoref{sec:idea} we showed how Bob's installation policy could be written using three \texttt{isMetBy} statements.
    Splitting policies allows greater control of how each one is checked.
    We can delegate checking a policy to an expert using the \code{can-say} statement.
    We can specify more detailed checks using the \code{can-act-as} statements.

  \item[\texttt{Policy shownIsMetBy(Evidence, App)}]
    A variant of the \texttt{isMetBy} statement that allows some evidence (a proof) to be given that shows the policy is met.
\end{description}

We also add the following constraint functions which check simple properties of the app:
In every case the check can be done by examining the app itself.
\begin{description}
  \item[\texttt{hasPermission(App, String)} : Bool]
    Checks the permissions requested in the app's manifest to see if the string is included in them.

  \item[\texttt{hasPackage(App, String)} : Bool]
    Checks the app to see if a package called \emph{String} is included within it.
    Examples might include aggressive advertisement frameworks a user wishes to ban.

  \item[\texttt{hasNativeCode(App)} : Bool]
    Checks to see whether the app contains native code.
    Native (i.e. non-Dalvik) code is potentially more dangerous than the sandboxed Dalvik versions.
    It is typically used for performance sensitive code (i.e. games).

  \item[\texttt{isSignedBy(App, Speaker)} : Bool]
    Checks the \texttt{CERT.RSA} used to sign the App and compares it with the certificate used to identify a speaker.

  \item[\texttt{hasVersion(App)} : Int]
    Gets the version number of an app.

  \item[\texttt{released(App)} : Date]
    Checks when the app was last updated and released.
\end{description}

We also add some constraints that do more complex checks:
\begin{description}
  \item[\texttt{googlePlayRating(App)} : Int]
    Used to get the review score (out of 5) from the Google Play store.
    This could be extended to other reviewers.

  \item[tool\texttt{Check(App, Config)} : Bool]
    Uses the \emph{tool} to run a check on an app.
    This allows static analysis tools to run inferences on apps on demand.
    Static analysis can be expensive for devices to perform.
    An alternative would be to query a database of results~\citep{Noel:2014vt}.

  \item[tool\texttt{CheckEvidence(App, Config, Evidence)} : Bool]
    Digital evidence and proof~carrying~code~\citep{Necula:1996tr,Stark:2009uc} allow you to check an analysis result without repeating it.
    In a mobile phone this can be preferable to doing the inference as draining batteries to perform checks is undesirable.
    Tools, such as \emph{evicheck}~\citep{Noel:2014vt}, can produce digital evidence for Android apps.
    This constraint function allows us to incorporate these tools into AppPAL policies.
\end{description}

subsection{Evaluation}

To evaluate AppPAL we implement the SecPAL evaluation rules shown in \autoref{fig:rules}.
We do not use the DatalogC~\citep{Li:2003ix}~based translation and evaluation algorithm suggested by \citeauthor{Becker:2006vh}.
Rather we implement the rules directly in Java. 
Brief pseudo-code is given in \autoref{fig:pseudocode}
Like \citeauthor{Becker:2006vh} we make use of an assertion context to store known statements.
We also store intermediate results to avoid re-computation.
On a mobile device memory is at a premium.
We would like to keep the context as small as possible.
To do this we allow some assertions to be imported at evaluation-time.

\begin{figure}
\[\footnotesize
% AC, D ⊧ A says B can-act-as C   AC, D ⊧ A says C verbphrase 
% ----------------------------------------------------------- (can-act-as)
%                 AC, D ⊧ A says B verbphrase
\infer[\text{\tiny can-act-as}]{
  AC, D \models \text{\tt A says B verbphrase}}{%
  AC, D \models \text{\tt A says B can-act-as C} & %
  AC, D \models \text{\tt A says C verbphrase}} 
\]
\[\footnotesize
% AC, ∞ ⊧ A says B can-say D fact   AC, D ⊧ B says fact
% ----------------------------------------------------- (can-say)
%                   AC, ∞ ⊧ A says fact
\infer[\text{\tiny can-say}]{
  AC, \infty \models \text{\tt A says fact}}{%
  AC, \infty \models \text{\tt A say B can-say $D$ fact} & %
  AC, D \models \text{\tt B says fact}} 
\]
\[\footnotesize
% (A says fact if fact₁, …, factₖ, c) ∈ AC
% AC, D ⊧ A says factᵢθ  ∀i ∈ {1…k}    ⊧cθ    vars(factθ) = ∅
% ----------------------------------------------------------- (cond)
%                    AC, D ⊧ A says factθ
\infer[\text{\tiny cond}]{
  AC, D \models \text{\tt A says fact$\theta$}}{
  \begin{array}{c}
    (\text{\tt A says fact if fact$_1$, \ldots, fact$_k$ where c}) \in AC \\
    \forall i \in 1\cdots k.\;AC, D \models \text{\tt A says fact$_i\theta$}
  \end{array} &
  \models \mathtt{c}\theta &
  \text{\sl vars}(\text{\tt fact$\theta$})}
\]
\caption{AppPAL's evaluation rules.}
\label{fig:rules}
\end{figure}

This gives us greater control of the evaluation and how the assertion context is created.
For example, when checking the \code{isAnApp} predicate; 
  we can fetch the assertion that the subject is an app based on the app in question.
Similarly when we use a statement from \emph{Bob} that \emph{Google-Play can-say} whether an app is purchasable;
  it is sensible to go fetch from the store whether the app is saleable and make Google say it then and there.

In SecPAL there is no notion of type.
All entities are either constants (effectively strings) or variables.
There is no differentiation made between a \emph{voiced} constant (one who speaks),
and a \emph{subject} (one that is the subject of a verb-phrase, or predicate argument).
In AppPAL the subjects are usually apps or policies.
Apps do not utter facts.
Consequently there is no need to check them as potential speakers of \emph{can-say} statements.
Similarly if a constant never appears as a subject of a statement, as most speakers don't,
  there is no need to check it as a possible subject for a \emph{can-act-as} statement.
We pre-process the assertion context to find \emph{voiced} and \emph{subject} constants.

\begin{figure}
\begin{minipage}[b]{0.5\linewidth}
\begin{lstlisting}[language=Ruby, basicstyle=\ttfamily\scriptsize, keywordstyle=\scriptsize\slshape, columns=flexible]
# ac, d |-? q (using previous-results table rt)
def evaluate(ac, rt, q, d)
  return rt[q, d] if rt.contains q, d
  p = cond(ac, rt, q, d)
  return (Proven, rt.update q, d, p) if p.isValid 
  p = canSay_CanActAs(ac, rt, q, d)
  return (Proven, rt.update q, d, p) if p.isValid 
  return (Failure, rt.update q, d, Failure)

# Try can-say and can-act-as
def canSay_CanActAs(ac, rt, q, d)
  ac.constants.each do |c| 
    if c.is_a :subject
      p = canActAs ac, rt, q, d
      return Proven if p.isValid
    elsif c.is_a :speaker
      p = canSay ac, rt, q d
      return Proven if p.isValid
  return Failure
\end{lstlisting}
\end{minipage}
\begin{minipage}[b]{0.5\linewidth}
\begin{lstlisting}[language=Ruby, basicstyle=\ttfamily\scriptsize, keywordstyle=\scriptsize\slshape, columns=flexible]
# Try cond rule
def cond(ac, rt, q, d)
  ac.add q.fetch if q.isFetchable
  ac.assertions.each do |a|
    if (u = q.unify a.consequent) &&
       (a = u.substitution a).variables == none
      return checkConditions ac, rt, a, d
  return Failure
    
# Evaluate the antecedents
def checkConditions(ac, rt, a, d)
  getVarSubstitutions(a, ac.constants).each do |s|
    sa = s.substitute a
    if sa.antecedents.all 
        { |a| evaluate(ac, rt, a, d).isValid }
      p = evaluateC sa.constraint
      return Proven if p.isValid
  return Failure
\end{lstlisting}
\end{minipage}
\caption{Partial-pseudocode for AppPAL evaluation.}
\label{fig:pseudocode}
\end{figure}

\subsection{Policy Examples}
\label{ssec:idioms}

In this section we give examples of policies and queries and show how they can be implemented in AppPAL.

\begin{description}
  \item[App white-listing by an IT department]
    Inside Bob's company employees in the IT department may white-list certain apps as installable.
    To do this Bob delegates to them to decide if something is installable.
    \begin{lstlisting}
"bob" says "it-department" can-say 0 App isInstallable.
    \end{lstlisting}
    Charlie and Diveena work in the IT department.
    When they have checked an app they say it is installable.
    \begin{lstlisting}
"bob" says "charlie" can-act-as "it-department".
"bob" says "diveena" can-act-as "it-department".

"charlie" says "com.facebook.katana" isInstallable.
"diveena" says "org.thoughtcrime.securesms" isInstallable.
    \end{lstlisting}

  \item[Overpriviliged applications]
    Alice is particularly worried about apps stealing her data.
    She knows that certain apps need certain permissions.
    For example a photography app needs access to the camera.
    She checks each app's permissions carefully for things that seem unusual.

    Alice's policy can be implemented by checking the permissions of the app, using constraints.
    \begin{lstlisting}
"alice" says App isInstallable
   if "permissionsPolicy" isMetBy(App).
"alice" says "permissionsPolicy" isMetBy(App)
   if App isAnApp
   where
      category(App, "Photography"),
      hasPermission(App, "ACCESS_COARSE_LOCATION") = False,
      hasPermission(App, "CAMERA") = True.
    \end{lstlisting}

    Discovering the \emph{normal} permissions for an app can be done by mining large stores of apps, or apps a user has previously installed.
    Alternately tools like Stowaway~\citep{Felt:2011kj} could be integrated to check apps.

  \item[Digital Evidence]
    In \autoref{ssec:language} we described how digital evidence could be used to decide if policies are met.
    Suppose a digital evidence generating tool, such as \emph{Evicheck}, can be used to check a policy.
    For example that no audio can be recorded without the users consent~\citep{Seghir:2014uq}.
    Using this tool someone generates a proof certificate that this property is met.
    This could be the developer of the app, a third party certification service, or someone else;
      when we check the proof we will find out if it is valid or not.
    \begin{lstlisting}
"alice" says Anyone can-say 0 
  "recording-consent" shownIsMetBy(Evidence, App).

"skb" says "recording-consent" 
  shownIsMetBy("evicheck://evidence123", App).

"alice" says "recording-consent" isMetBy(App)
  if "recording-consent" shownIsMetBy(Evidence, App)
  where
    evicheckCheckEvidence(Evidence, App) = True. 
    \end{lstlisting}
    In the example here Alice allows anyone to present her with evidence for her policy.
    A \ac{skb} offers an some evidence, and Alice accepts it as if it checks out.
\end{description}

\section{Related work \comment{1--2 pages}}

There has been a great amount of work on developing app analysis tools for Android.  
Tools such as Stowaway~\citep{Felt:2011kj} detect overprivileged apps.
TaintDroid~\citep{Enck:2010uw} and FlowDroid~\citep{Fritz:2013vi} can do taint and control flow analysis; sometimes even between app components.
Other tools like QUIRE~\citep{Bugiel:2012ui} can find privilege escalation attacks between entire apps.
ScanDAL~\citep{Kim:2012vt} and SCanDroid~\citep{Fuchs:2009vi} help detect privacy leaks.
Appscopy~\citep{Feng:kPGZr_ja} searches for specific kinds of malware.
Tools like DroidRanger~\citep{Zhou:2012tb} scan app markets for malicious apps. 
Many others exist checking and certifying other aspects of app behaviour.

One tool, Kirin~\citep{Enck:2009ko}, also created a policy language and tool for enforcing app installation policies.
Kirin's policies were concerned with preventing malware.
Policy authors could specify combinations of permissions that should not appear together.
For example an author might wish to stop malware sending premium rate text messages.
To do this they restrict an app having both the \texttt{SEND\_SMS} and \texttt{WRITE\_SMS} permissions (\autoref{fig:kirin}).
Using this approach they found vulnerabilities in Android, but were ultimately limited by being restricted to permissions and broadcast events.
\begin{figure}
\begin{lstlisting}
restrict permission [SEND_SMS] and permission [WRITE_SMS]
\end{lstlisting}
\begin{lstlisting}
"user" says "no-write-send-sms" isMetBy(App)
  where hasPermission(App, "SEND_SMS") = False.
"user" says "no-write-send-sms" isMetBy(App)
  where hasPermission(App, "WRITE_SMS") = False.
\end{lstlisting}
\caption{Kirin and AppPAL policies for stopping apps monetized by premium rate text messages.}
\label{fig:kirin}
\end{figure}

Whilst this approach is great for malware, it is less suitable for finding \ac{pus}.
The behaviours and permissions \ac{pus} apps display aren't necessarily malicious.
One user may consider apps which need in-app-purchases to play malware, but another may enjoy them.
AppPAL tries to stop these \ac{pus} apps.
Because we can use external checking tools which go further than permissions checks, our policies can be richer.
By allowing delegation relationships we can understand the provenance and trust relationships in these rules.

Work by \citeauthor{Sadeh:2014vq} looked at modelling users' willingness to grant different kinds of permissions~\citep{Sadeh:2014vq}.
They found four clusters of different users each with different kinds of policies:
  conservatives who don't like granting many permissions,
  advanced users who seem to have more complex policies,
  unconcerned users who'll comfortably grant anything,
  and fence-sitters (about half of all users) who seemed not to really care the majority of the time.
This suggests that users are applying policies and do care how apps behave.
Further more \citeauthor{Sadeh:2014vq} speculate that the fence-sitters seemed not to care because of \emph{warning fatigue}.
This suggests a system like AppPAL that can reduce user interaction with permission warnings might be interesting.
Using a policy unconcerned and fence-sitting users could take up more privacy preserving policies without having to change their behavior.

We picked SecPAL as the basis for AppPAL because it was readable, extensible, and seemed to be a good fit for the problem we were trying to solve~\citep{Hallett:2014un}.
Further more attempts to apply it to other areas had already succeeded~\citep{Aziz:2011vt,Humphrey:2007wc}.
Other policy languages such as RT~\citep{Li:2003ua}, or Cassandra~\citep{Becker:2004il} might also have made a good starting point.
However neither had the precise set of features we we're looking for (namely explicit speakers and external checking functions).
Other work on SecPAL has added various features such as existential quantification~\citep{Becker:2009vt} and ultimately becoming the DKAL family of policy languages~\citep{Gurevich:2008fz,Gurevich:Qo5E3M3}.
\citeauthor{Gurevich:2008fz} showed that SecPAL was a subset of DKAL (minus the \emph{can-act-as} statement).
DKAL also contains more modalities than \emph{says}.


\section{Conclusions and further work \comment{$\frac{1}{2}$ page}}

We have presented AppPAL: an authorization logic for describing app installation policies.
The language is implemented in Java and runs on Android using a custom evaluation algorithm.
This allows us to enforce app installation policies on Android devices.
We've shown how the language can be used to describe an app installation policy;
  and given brief descriptions of how other policies might be described.

Further work is required to tightly integrate AppPAL into Android.
The obvious place to put it would be as a \emph{required checker}: a program that checks all apps before installation.
Google currently use this API to check for known malware and jailbreak apps.
We would like AppPAL to sit there and check apps on the basis of policies.
Unfortunately the API is protected and it would require the phone to be rooted to run there.

Developing, and testing, policies for users is a key next step.
Here we described a policy being specified by a company boss.
For most end-users writing a policy in a formal language is too much work.
Ad-blocking software works by users subscribing to filter policies written by experts\footnote{EasyList is a popular choice and the default in most ad-blocking software. They offer many different policies for specific use-cases however. \url{https://easylist.adblockplus.org/en/}}.
We can imagine a similar scheme working well for app installation policies.
Users subscribe to different policies by experts (e.g. no tracking apps, nothing with adult content, no spammy in-app-purchase apps).
Optionally they can customize them further.

We should also attempt to learn policies from existing users behavior.
Given app usage data, from a project like Carat~\citep{Oliner:2013ht}, we could identify security conscious users.
If we can infer these users policies we may be able to describe new policies that the less technical users may want.
Given a set of apps one user has already installed, we could learn policies about what their personal installation policy is.
This may help stores show users apps they're more likely to buy, and users apps that already behave as they want.

AppPAL is a powerful language for describing app installation policies.
It gives us a framework for describing and evaluating policies for Android apps.
The work provides new ways for users to enforce their own rules about how apps should behave.
Users policies can be enforced more reliably, and with less interaction;
thus making apps more pleasant and safer for everyone.

\bibliographystyle{plainnat}
\bibliography{paper}
\end{document}
